{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast, BertModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "from torch import nn\n",
        "import pandas as pd\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import string"
      ],
      "metadata": {
        "id": "IBe2XI2q9Fq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfFfkI4L8_y6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/SQuAD/train-squad.csv'\n",
        "val_path = '/content/drive/MyDrive/SQuAD/validation-squad.csv'"
      ],
      "metadata": {
        "id": "QspBICHl-K0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokeniser = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n"
      ],
      "metadata": {
        "id": "id1fMTsT9GL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class eQA(Dataset):\n",
        "  def __init__(self,csv_path) -> None:\n",
        "    super().__init__()\n",
        "    self.df = pd.read_csv(csv_path)\n",
        "    self.df[\"text\"] = self.df[\"text\"].fillna(\"\")\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "  def __getitem__(self,idx):\n",
        "    row = self.df.iloc[idx]\n",
        "    return {\n",
        "        \"context\": row[\"context\"],\n",
        "        \"question\": row[\"question\"],\n",
        "        \"id\": row[\"id\"],\n",
        "        \"answer_start\": row[\"answer_start\"],\n",
        "        \"answer\": row[\"text\"]\n",
        "    }\n"
      ],
      "metadata": {
        "id": "PRZyc8zN_N4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "  encoding = tokeniser([sample[\"context\"] for sample in batch],\n",
        "                        [sample[\"question\"] for sample in batch],\n",
        "                        padding = \"max_length\",\n",
        "                        truncation = True,\n",
        "                        return_offsets_mapping = True,\n",
        "                        max_length = 512,\n",
        "                        return_tensors = \"pt\")\n",
        "  #get the index of the start index and end index\n",
        "  start_positions = []\n",
        "  end_positions = []\n",
        "  for i,s in enumerate(batch):\n",
        "    answer_start = s[\"answer_start\"]\n",
        "    answer_end = answer_start + len(s[\"answer\"])\n",
        "    offset = encoding[\"offset_mapping\"][i]\n",
        "    start_pos, end_pos = 0, 0\n",
        "    for j, (start,end) in enumerate(offset):\n",
        "      if start <= answer_start < end:\n",
        "        start_pos = j\n",
        "      if start < answer_end <= end:\n",
        "        end_pos = j\n",
        "    start_positions.append(start_pos)\n",
        "    end_positions.append(end_pos)\n",
        "\n",
        "  tensor_start = torch.tensor(start_positions)\n",
        "  tensor_end = torch.tensor(end_positions)\n",
        "\n",
        "  encoding.pop(\"offset_mapping\")\n",
        "\n",
        "  encoding[\"start_positions\"] = tensor_start\n",
        "  encoding[\"end_positions\"] = tensor_end\n",
        "\n",
        "  return encoding\n"
      ],
      "metadata": {
        "id": "7d9wMy2nC2Tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn_val(batch):\n",
        "  encoding = tokeniser([sample[\"context\"] for sample in batch],\n",
        "                        [sample[\"question\"] for sample in batch],\n",
        "                        padding = \"max_length\",\n",
        "                        truncation = True,\n",
        "                        return_offsets_mapping = True,\n",
        "                        max_length = 512,\n",
        "                        return_tensors = \"pt\")\n",
        "  #get the index of the start index and end index\n",
        "  start_positions = []\n",
        "  end_positions = []\n",
        "  for i,s in enumerate(batch):\n",
        "    answer_start = s[\"answer_start\"]\n",
        "    answer_end = answer_start + len(s[\"answer\"])\n",
        "    offset = encoding[\"offset_mapping\"][i]\n",
        "    start_pos, end_pos = 0, 0\n",
        "    for j, (token_start,token_end) in enumerate(offset):\n",
        "      if token_start <= answer_start < token_end:\n",
        "        start_pos = j\n",
        "      if token_start < answer_end <= token_end:\n",
        "        end_pos = j\n",
        "    start_positions.append(start_pos)\n",
        "    end_positions.append(end_pos)\n",
        "\n",
        "  tensor_start = torch.tensor(start_positions)\n",
        "  tensor_end = torch.tensor(end_positions)\n",
        "\n",
        "  encoding[\"start_positions\"] = tensor_start\n",
        "  encoding[\"end_positions\"] = tensor_end\n",
        "  encoding[\"context\"] = [s[\"context\"] for s in batch]\n",
        "  encoding[\"answer\"] = [s[\"answer\"] for s in batch]\n",
        "\n",
        "  return encoding\n"
      ],
      "metadata": {
        "id": "QTYWOswKqi3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = eQA(train_path)\n",
        "valset = eQA(val_path)\n",
        "raw_batch_data = [trainset[i] for i in range(3)]\n",
        "\n",
        "print(collate_fn(raw_batch_data))"
      ],
      "metadata": {
        "id": "0bYy6LmDCjOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(trainset, batch_size=8, collate_fn=collate_fn)\n",
        "valLoader = DataLoader(valset, batch_size=8, collate_fn=collate_fn_val)\n"
      ],
      "metadata": {
        "id": "O3g6C7QFObz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTMBERT(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super().__init__()\n",
        "    self.embeddings = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "    self.embeddings.requires_grad_(False)\n",
        "\n",
        "    hidden_size = self.embeddings.config.hidden_size\n",
        "    self.lstm = nn.LSTM(hidden_size, hidden_size, bidirectional=True, batch_first=True)\n",
        "    self.output1 = nn.Linear(hidden_size * 2, 1)\n",
        "    self.output2 = nn.Linear(hidden_size * 2, 1)\n",
        "\n",
        "  def forward(self, input_ids, token_type, attention_mask):\n",
        "    state = self.embeddings(input_ids, attention_mask = attention_mask, token_type_ids = token_type).last_hidden_state\n",
        "    proc,_ = self.lstm(state)\n",
        "    start_logits = self.output1(proc)\n",
        "    end_logits = self.output2(proc)\n",
        "    return start_logits, end_logits\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7i9bgIOfPcEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "model = BiLSTMBERT().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimiser = Adam(model.parameters(), lr = 0.001)\n"
      ],
      "metadata": {
        "id": "yQpfkEJUaTCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "  m = 0\n",
        "  running_loss = 0\n",
        "  progress_bar = tqdm(trainloader, desc=f\"Epoch {epoch+1}\")\n",
        "  for batch in progress_bar:\n",
        "    input_ids = batch[\"input_ids\"].to(device)\n",
        "    token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "    attention_mask = batch[\"attention_mask\"].to(device)\n",
        "    start = batch[\"start_positions\"].to(device)\n",
        "    end = batch[\"end_positions\"].to(device)\n",
        "\n",
        "\n",
        "    start_logits, end_logits = model(input_ids,token_type_ids,attention_mask)\n",
        "    start_logits = start_logits.squeeze(-1)\n",
        "    end_logits = end_logits.squeeze(-1)\n",
        "\n",
        "    loss_start = loss_fn(start_logits,start)\n",
        "    loss_end = loss_fn(end_logits, end)\n",
        "    loss_avg = (loss_start + loss_end) / 2\n",
        "\n",
        "    progress_bar.set_postfix(loss=loss_avg.item())\n",
        "\n",
        "    optimiser.zero_grad()\n",
        "    loss_avg.backward()\n",
        "    optimiser.step()\n",
        "  validate(model,valLoader,\"cuda\",epoch)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MCfytGgLbK2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, valLoader, device, epoch):\n",
        "    model.eval()\n",
        "    total_em = 0\n",
        "    total_f1 = 0\n",
        "    n = 0\n",
        "\n",
        "    def normalise(text):\n",
        "        return text.lower().translate(str.maketrans(\"\", \"\", string.punctuation)).strip()\n",
        "\n",
        "    def compute_f1(pred, truth):\n",
        "        pred_tokens = normalise(pred).split()\n",
        "        truth_tokens = normalise(truth).split()\n",
        "        common = set(pred_tokens) & set(truth_tokens)\n",
        "        if len(common) == 0:\n",
        "            return 0.0\n",
        "        precision = len(common) / len(pred_tokens)\n",
        "        recall = len(common) / len(truth_tokens)\n",
        "        return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(valLoader, desc=f\"Epoch {epoch+1}\")\n",
        "        for batch in progress_bar:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            token_type_ids = batch[\"token_type_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            start = batch[\"start_positions\"].to(device)\n",
        "            end = batch[\"end_positions\"].to(device)\n",
        "            offset = batch[\"offset_mapping\"]\n",
        "\n",
        "            start_logits, end_logits = model(input_ids, token_type_ids, attention_mask)\n",
        "            start_logits = start_logits.squeeze(-1)\n",
        "            end_logits = end_logits.squeeze(-1)\n",
        "\n",
        "            predicted_start = torch.argmax(start_logits, dim=-1)\n",
        "            predicted_end = torch.argmax(end_logits, dim=-1)\n",
        "\n",
        "            for i in range(len(predicted_start)):\n",
        "                offsets = batch[\"offset_mapping\"][i]\n",
        "                context = batch[\"context\"][i]\n",
        "                answer = batch[\"answer\"][i]\n",
        "\n",
        "                i_start = predicted_start[i].item()\n",
        "                i_end = predicted_end[i].item()\n",
        "\n",
        "                start_char, _ = offsets[i_start]\n",
        "                _, end_char = offsets[i_end]\n",
        "\n",
        "                predicted_text = context[start_char:end_char]\n",
        "                gt_text = answer\n",
        "\n",
        "                print(f\"GT: {gt_text}\")\n",
        "                print(f\"Pred: {predicted_text}\")\n",
        "\n",
        "                em = int(normalise(predicted_text) == normalise(gt_text))\n",
        "                f1 = compute_f1(predicted_text, gt_text)\n",
        "\n",
        "                total_em += em\n",
        "                total_f1 += f1\n",
        "\n",
        "                n += 1\n",
        "\n",
        "    print(f\"Validation EM: {total_em / n}\")\n",
        "    print(f\"Validation f1: {total_f1 / n}\")"
      ],
      "metadata": {
        "id": "OYUFIyfZlCVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/SQuAD/model.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "w2Vb7A03ZQJe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}